{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:22: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "from utils import Tools\n",
    "tools = Tools('mhk9c')\n",
    "spark = tools.spark\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Create features\n",
    "import emoji\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "import demoji \n",
    "demoji.download_codes()\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = tools.create_df_from_csv(\"russian-troll-tweets-master\")\n",
    "# tools.save_df(df, 'russian-troll-tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = tools.load_data(\"russian-troll-tweets\")\n",
    "# df_english = df.filter(df['language']=='English')\n",
    "# tools.save_df(df_english, \"russian-troll-tweets-english-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading from /project/ds5559/team1_sp22/data//russian-troll-tweets-english-only.\n"
     ]
    }
   ],
   "source": [
    "df = tools.load_data(\"russian-troll-tweets-english-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- external_author_id: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- publish_date: string (nullable = true)\n",
      " |-- harvested_date: string (nullable = true)\n",
      " |-- following: integer (nullable = true)\n",
      " |-- followers: integer (nullable = true)\n",
      " |-- updates: integer (nullable = true)\n",
      " |-- post_type: string (nullable = true)\n",
      " |-- account_type: string (nullable = true)\n",
      " |-- retweet: integer (nullable = true)\n",
      " |-- account_category: string (nullable = true)\n",
      " |-- new_june_2018: integer (nullable = true)\n",
      " |-- alt_external_id: string (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- article_url: string (nullable = true)\n",
      " |-- tco1_step1: string (nullable = true)\n",
      " |-- tco2_step1: string (nullable = true)\n",
      " |-- tco3_step1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Munging after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "import re\n",
    "rx_b = re.compile(r\"@[a-zA-Z0-9]+\")\n",
    "rx_url = re.compile(r\"(?:http|ftp|https):\\/\\/(?:[\\w_-]+(?:(?:\\.[\\w_-]+)+))(?:[\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\")\n",
    "\n",
    "\n",
    "# *************************************************************\n",
    "def convert_emojii(string): \n",
    "    '''\n",
    "    convert emoji to string representation with demoji\n",
    "    '''\n",
    "    try:\n",
    "        return demoji.replace_with_desc(string, \":\")\n",
    "    except:\n",
    "        return \"COULD NOT CONVERT EMOJII\"\n",
    "convert_emojii_UDF = func.udf(lambda z:convert_emojii(z),StringType())   \n",
    "# test = convert_emojii(\"üêùüêùüêù\")   \n",
    "# print(test)\n",
    "\n",
    "# *************************************************************\n",
    "def extract_domain_information(url):  \n",
    "    '''\n",
    "    Extract domain information with tldextract\n",
    "        Attempts to get registered domain if not parses out domain information from url\n",
    "    '''\n",
    "    try:        \n",
    "        if(url):            \n",
    "            ext = tldextract.extract(url)\n",
    "            if(ext.registered_domain):                \n",
    "                return ext.registered_domain\n",
    "            else :                \n",
    "                return f'{ext.subdomain}.{ext.domain}.{ext.suffix}'                \n",
    "        else:            \n",
    "            return \"NA\"        \n",
    "    except Exception as e:        \n",
    "        return \"NA\"    \n",
    "extract_domain_information_UDF = func.udf(lambda z:extract_domain_information(z),StringType())   \n",
    "# test = extract_domain_information(\"http://yhoo.it/1QjSSWw\")\n",
    "\n",
    "# *************************************************************\n",
    "def extract_handles(content): \n",
    "    '''\n",
    "        gets all the handles in the tweet of the form @[a-zA-Z0-9]+ and returns an array\n",
    "    '''\n",
    "    try:\n",
    "        if(content is not None):        \n",
    "            result = re.findall(rx_b, content) \n",
    "            return result\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []    \n",
    "extract_handles_UDF = func.udf(lambda z:extract_handles(z),ArrayType(StringType(), True))   \n",
    "# test = extract_handles(\"Hi @MichelleObama , remember when you praised Harvey Weinstein as 'a wonderful human being, a good friend and a powerhouse.\")\n",
    "# print(test)\n",
    "\n",
    "# *************************************************************\n",
    "def count_emoji(string):\n",
    "    '''\n",
    "    Count number of emojis within a string\n",
    "    '''\n",
    "    if string:\n",
    "        return emoji.emoji_count(string)\n",
    "    else:\n",
    "        return 0\n",
    "count_emoji_udf = func.udf(lambda x: count_emoji(x), IntegerType())\n",
    "\n",
    "# *************************************************************\n",
    "def extract_emoji(string):\n",
    "    '''\n",
    "    Extract emojis by converting them to text\n",
    "    '''\n",
    "    if string:\n",
    "        return emoji.demojize(emoji.distinct_emoji_lis(string))\n",
    "    else:\n",
    "        return 'None'\n",
    "extract_emoji_udf = func.udf(lambda x: extract_emoji(x), StringType())\n",
    "\n",
    "# *************************************************************\n",
    "def extract_urls(string):\n",
    "    '''\n",
    "    Extract all urls in string\n",
    "    '''\n",
    "    if string:\n",
    "#         urls = re.findall('(?:(?:https?|ftp):\\\\/\\\\/)?[\\\\w/\\\\-?=%.]+\\\\.[\\\\w/\\\\-&?=%.]+', string)\n",
    "        urls = re.findall(rx_url, string)\n",
    "\n",
    "        return urls\n",
    "    else:\n",
    "        return 'None'\n",
    "extract_urls_udf = func.udf(lambda x: extract_urls(x), StringType())\n",
    "\n",
    "# *************************************************************\n",
    "def url_count(string):\n",
    "    '''\n",
    "    Count all urls in string\n",
    "    '''\n",
    "    if string:\n",
    "        return(len(extract_urls(string)))\n",
    "    else:\n",
    "        return 0\n",
    "url_count_udf = func.udf(lambda x: url_count(x), IntegerType())\n",
    "\n",
    "# *************************************************************\n",
    "def extract_url_parts(string):\n",
    "    '''\n",
    "    Return url in parts (https://stackoverflow.com/questions/27745/getting-parts-of-a-url-regex)\n",
    "    '''\n",
    "    if string:\n",
    "        return re.findall('^((http[s]?|ftp):\\/)?\\/?([^:\\/\\s]+)((\\/\\w+)*\\/)([\\w\\-\\.]+[^#?\\s]+)(.*)?(#[\\w\\-]+)?$', string)\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "def extract_urls_redirect_base(string_1, string_2, string_3):\n",
    "    '''\n",
    "    Call extract_url_parts and create a list of hosts from twitters redirect columns\n",
    "    '''\n",
    "    try:\n",
    "        host_list = ['', '', '']\n",
    "        if string_3:\n",
    "            url_parts = extract_url_parts(string_3)\n",
    "            host_list[2] = url_parts[0][2]\n",
    "        if string_2:\n",
    "            url_parts = extract_url_parts(string_2)\n",
    "            host_list[1] = url_parts[0][2]\n",
    "        if string_1:\n",
    "            url_parts = extract_url_parts(string_1)\n",
    "            host_list[0] = url_parts[0][2]\n",
    "        else:\n",
    "            return 'None'\n",
    "    except:\n",
    "        return 'None'\n",
    "    return host_list\n",
    "extract_urls_redirect_base_udf = func.udf(lambda x,y,z: extract_urls_redirect_base(x,y,z), StringType())\n",
    "\n",
    "# *************************************************************\n",
    "def word_count(string):\n",
    "    '''\n",
    "    Count number of words in string (slightly error prone b/c split on spaces)\n",
    "    '''\n",
    "    if string:\n",
    "        return len(string.split(' '))\n",
    "    else:\n",
    "        return 0\n",
    "word_count_udf = func.udf(lambda x: word_count(x), IntegerType())\n",
    "\n",
    "# *************************************************************\n",
    "def character_count(string):\n",
    "    '''\n",
    "    Count number of characters in the tweet\n",
    "    '''\n",
    "    if string:\n",
    "        return len(string)\n",
    "    else: \n",
    "        return 0\n",
    "character_count_udf = func.udf(lambda x: character_count(x), IntegerType())\n",
    "\n",
    "# *************************************************************\n",
    "def extract_date_info(string, info_type):\n",
    "    '''\n",
    "    IN WORK\n",
    "    Extract date info\n",
    "    '''\n",
    "    date = datetime.datetime.strptime(string, '%m/%d/%Y %H:%M')\n",
    "    \n",
    "    if info_type == 'minute':\n",
    "        info = date.minute\n",
    "    elif info_type == 'hour':\n",
    "        info = date.hour\n",
    "    elif info_type == 'day':\n",
    "        info = date.day\n",
    "    elif info_type == 'month':\n",
    "        info = date.month\n",
    "    elif info_type == 'year':\n",
    "        info = date.year    \n",
    "    return info\n",
    "extract_date_info_udf = func.udf(lambda x,y: extract_date_info(x,y), IntegerType())\n",
    "\n",
    "# *************************************************************\n",
    "\n",
    "def assignLabel(account_category):\n",
    "    '''\n",
    "        Assigns 1 - troll, or 0 - not-troll as a label to the tweet.\n",
    "    '''\n",
    "    if account_category in (\"RightTroll\", \"LeftTroll\" , \"Fearmonger\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "# test = assignLabel(\"Commercial\")\n",
    "# print(test)\n",
    "assignLabel_udf = func.udf(assignLabel, IntegerType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving File...\n",
      "/project/ds5559/team1_sp22/data/russian-troll-tweets-enriched\n",
      "Saved as: /project/ds5559/team1_sp22/data/russian-troll-tweets-enriched\n"
     ]
    }
   ],
   "source": [
    "df_enriched = df.withColumn(\"curated_content\", convert_emojii_UDF(col(\"content\"))) \\\n",
    "                .withColumn(\"tco1_step1_domain\", extract_domain_information_UDF(col(\"tco1_step1\"))) \\\n",
    "                .withColumn(\"tco2_step1_domain\", extract_domain_information_UDF(col(\"tco2_step1\"))) \\\n",
    "                .withColumn(\"tco3_step1_domain\", extract_domain_information_UDF(col(\"tco3_step1\"))) \\\n",
    "                .withColumn(\"handles\", extract_handles_UDF(col(\"content\"))) \\\n",
    "                .withColumn('emoji_count', count_emoji_udf(col('content'))) \\\n",
    "                .withColumn('emoji_text', extract_emoji_udf(col('content'))) \\\n",
    "                .withColumn('word_count', word_count_udf(col('content'))) \\\n",
    "                .withColumn('char_count', character_count_udf(col('content'))) \\\n",
    "                .withColumn('urls', extract_urls_udf(col('content'))) \\\n",
    "                .withColumn('url_count', url_count_udf(col('content'))) \\\n",
    "                .withColumn('url_hosts', extract_urls_redirect_base_udf(col('tco1_step1'), col('tco2_step1'), col('tco3_step1'))) \\\n",
    "                .withColumn('label',assignLabel_udf(df['account_category']))\n",
    "\n",
    "# There is one row without content..\n",
    "df_enriched = df_enriched.dropna(subset=\"content\")\n",
    "print(\"Saving File...\")\n",
    "tools.save_df(df_enriched, \"russian-troll-tweets-enriched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading from /project/ds5559/team1_sp22/data//russian-troll-tweets-enriched.\n"
     ]
    }
   ],
   "source": [
    "df_test = tools.load_data(\"russian-troll-tweets-enriched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.select(['content','handles']).show(5, False)\n",
    "df_test.filter(\"content like '%LindseyGrahamSC%'\" ).select(['content','urls']).show(5, False)\n",
    "# df.filter(\"content like '%LindseyGrahamSC%'\" ).select(['content']).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.createOrReplaceTempView(\"tweets\")\n",
    "sqlDF = spark.sql(\"SELECT tco1_step1_domain, count(tco1_step1_domain) FROM tweets GROUP BY tco1_step1_domain ORDER BY COUNT(tco1_step1_domain) DESC\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b load pyspark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_content = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "remover_content = StopWordsRemover(inputCol=\"words\", outputCol=\"words_filtered\")\n",
    "htf_content = HashingTF(inputCol=\"words_filtered\", outputCol=\"content_htf\", numFeatures=200)  \n",
    "\n",
    "va = VectorAssembler(inputCols=[\"content_htf\"], outputCol=\"features\")  \n",
    "lr = LogisticRegression(labelCol='label', featuresCol='features', maxIter=10, regParam=0.01)\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "                            tok_content\n",
    "                            ,remover_content\n",
    "                            ,htf_content                            \n",
    "                            ,va\n",
    "                            ,lr])\n",
    "# model = pipeline.fit(training)\n",
    "model = pipeline.fit(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_bad = split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_bad.select(['content', 'external_author_id', 'publish_date']).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.createOrReplaceTempView(\"tweets\")\n",
    "sqlDF = spark.sql(\"SELECT content, external_author_id from tweets where content IS NULL\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = last_bad.dropna(subset=\"content\")\n",
    "print('*')\n",
    "test.filter(\"content is NULL\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://csyhuang.github.io/2020/08/01/custom-transformer/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
